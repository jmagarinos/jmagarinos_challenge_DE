{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 20), 'SivaKum66642898'), (datetime.date(2021, 2, 17), 'RanjeetSinghMK'), (datetime.date(2021, 2, 23), 'Cuttack_IYC'), (datetime.date(2021, 2, 15), 'ajityadavdu'), (datetime.date(2021, 2, 15), 'bot_shiv'), (datetime.date(2021, 2, 17), 'Gurchar49439958'), (datetime.date(2021, 2, 23), 'Preetm91'), (datetime.date(2021, 2, 16), 'Monica_Gill1'), (datetime.date(2021, 2, 24), 'NavNarinder'), (datetime.date(2021, 2, 17), 'Monica_Gill1')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    all_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(file_path):\n",
    "        if 'day=' in os.path.basename(root):\n",
    "            parquet_files = [os.path.join(root, file) for file in files if file.endswith('.parquet') and file != '.DS_Store']\n",
    "            if parquet_files:\n",
    "                all_files.extend(parquet_files)\n",
    "    \n",
    "    if not all_files:\n",
    "        raise ValueError(\"No parquet files found in the specified directory.\")\n",
    "\n",
    "    try:\n",
    "        df = pd.concat([pd.read_parquet(file) for file in all_files], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading parquet files: {e}\")\n",
    "\n",
    "    if 'date' not in df.columns or 'user' not in df.columns:\n",
    "        raise KeyError(\"'date' or 'user' column not found in the DataFrame.\")\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    grouped = df.groupby('date').size().reset_index(name='tweet_count')\n",
    "\n",
    "    top_dates = grouped.sort_values(by='tweet_count', ascending=False).head(10)\n",
    "\n",
    "    result = []\n",
    "    for _, row in top_dates.iterrows():\n",
    "        date = row['date']\n",
    "        daily_df = df[df['date'] == date]\n",
    "        top_user = daily_df['user'].value_counts().idxmax()\n",
    "        user_info = daily_df[daily_df['user'] == top_user]['user'].iloc[0] \n",
    "        \n",
    "        username = user_info['username']\n",
    "        \n",
    "        result.append((date.date(), username))\n",
    "\n",
    "    return result\n",
    "\n",
    "file_path = '/Users/juanignaciomagarinoscastro/Downloads/tweets_by_date'\n",
    "result = q1_time(file_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 20), 'SivaKum66642898'), (datetime.date(2021, 2, 17), 'RaaJVinderkaur'), (datetime.date(2021, 2, 23), 'AlamGahir'), (datetime.date(2021, 2, 15), 'ajityadavdu'), (datetime.date(2021, 2, 15), 'ajityadavdu'), (datetime.date(2021, 2, 17), 'ajityadavdu'), (datetime.date(2021, 2, 23), 'Preetm91'), (datetime.date(2021, 2, 16), 'Monica_Gill1'), (datetime.date(2021, 2, 24), 'NavNarinder'), (datetime.date(2021, 2, 17), 'Monica_Gill1')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    all_files = []\n",
    "    \n",
    "    # Walk through the directories to gather Parquet files\n",
    "    for root, dirs, files in os.walk(file_path):\n",
    "        if 'day=' in os.path.basename(root):\n",
    "            parquet_files = [os.path.join(root, file) for file in files if file.endswith('.parquet') and file != '.DS_Store']\n",
    "            if parquet_files:\n",
    "                all_files.extend(parquet_files)\n",
    "    \n",
    "    if not all_files:\n",
    "        raise ValueError(\"No parquet files found in the specified directory.\")\n",
    "\n",
    "    try:\n",
    "        df = pd.concat([pd.read_parquet(file) for file in all_files], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading parquet files: {e}\")\n",
    "\n",
    "    # Check for required columns\n",
    "    if 'date' not in df.columns or 'user' not in df.columns:\n",
    "        raise KeyError(\"'date' or 'user' column not found in the DataFrame.\")\n",
    "\n",
    "    # Convert date column to datetime and ensure it's in the correct format\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Extract the username from the 'user' field if it's a dictionary\n",
    "    user_col = 'user'\n",
    "    if isinstance(df[user_col].iloc[0], dict):\n",
    "        df['username'] = df[user_col].apply(lambda x: x.get('username', '') if isinstance(x, dict) else x)\n",
    "    else:\n",
    "        df['username'] = df[user_col]  # If 'user' is already a string, just use it\n",
    "\n",
    "    # Group by date and username, and count the occurrences\n",
    "    user_tweet_count = df.groupby(['date', 'username']).size().reset_index(name='tweet_count')\n",
    "\n",
    "    # Find the top 10 dates with the most tweets\n",
    "    date_tweet_count = df.groupby('date').size().reset_index(name='tweet_count')\n",
    "    top_dates = date_tweet_count.sort_values(by='tweet_count', ascending=False).head(10)\n",
    "\n",
    "    result = []\n",
    "    for _, row in top_dates.iterrows():\n",
    "        date = row['date']\n",
    "        # Filter the DataFrame for the current date\n",
    "        daily_df = user_tweet_count[user_tweet_count['date'] == date]\n",
    "        \n",
    "        # Find the user with the most tweets for the current date\n",
    "        top_user_row = daily_df.sort_values(by='tweet_count', ascending=False).iloc[0]\n",
    "        top_user = top_user_row['username']\n",
    "\n",
    "        # Append the result as (date, top_user)\n",
    "        result.append((date.date(), top_user))\n",
    "\n",
    "    return result\n",
    "\n",
    "# Test the function\n",
    "file_path = '/Users/juanignaciomagarinoscastro/Downloads/tweets_by_date'\n",
    "result = q1_time(file_path)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'jot__b'),\n",
       " (datetime.date(2021, 2, 18), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 15), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 20), 'Preetm91'),\n",
       " (datetime.date(2021, 2, 23), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 19), 'Surrypuria')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str, int]]:\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        #Cargar archivo json linea a linea\n",
    "        data = [json.loads(line.strip()) for line in json_file]\n",
    "    #Usar una list comprenhension para extraer los campos\n",
    "    data = [(item['date'], item['user']['username'], item['id']) for item in data if 'date' in item and 'user' in item and 'id' in item and 'id' in item['user']]\n",
    "\n",
    "    #Convertir la lista de tuplas en un dataframe de pandas\n",
    "    df = pd.DataFrame(data, columns=['date', 'user', 'id'])\n",
    "    \n",
    "    # Convertir campo date en formato datetime\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    tweet_counts = df.groupby('date').size()\n",
    "    top_10_dates = tweet_counts.nlargest(10).index\n",
    "    df_top_10 = df[df['date'].isin(top_10_dates)]\n",
    "    top_users = df_top_10.groupby('date')['user'].agg(lambda x: x.value_counts().index[0])\n",
    "\n",
    "    # Convertir el resulatado en una lista de tuplas\n",
    "    result = [(date, user) for date, user in zip(top_10_dates, top_users)]\n",
    "    \n",
    "    return result\n",
    "\n",
    "file_path='/Users/juanignaciomagarinoscastro/Downloads/farmers-protest-tweets-2021-2-4.json'\n",
    "q1_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'jot__b'),\n",
       " (datetime.date(2021, 2, 18), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 15), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 20), 'Preetm91'),\n",
       " (datetime.date(2021, 2, 23), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 19), 'Surrypuria')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Leer el archivo JSON línea por línea y procesarlo\n",
    "    data = []\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        for line in json_file:\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                # Verificar que los campos necesarios están presentes antes de agregar\n",
    "                if 'date' in item and 'user' in item and 'id' in item:\n",
    "                    data.append((item['date'], item['user']['username']))\n",
    "            except json.JSONDecodeError:\n",
    "                # Manejar errores de decodificación JSON\n",
    "                continue\n",
    "    \n",
    "    # Convertir la lista de tuplas en un DataFrame de pandas\n",
    "    df = pd.DataFrame(data, columns=['date', 'user'])\n",
    "    \n",
    "    # Convertir el campo 'date' a formato datetime directamente sin conversiones intermedias\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # Calcular la cantidad de tweets por fecha y encontrar las 10 fechas con más tweets\n",
    "    tweet_counts = df['date'].value_counts().nlargest(10)\n",
    "    top_10_dates = tweet_counts.index\n",
    "\n",
    "    # Filtrar el DataFrame para incluir solo las fechas top 10\n",
    "    df_top_10 = df[df['date'].isin(top_10_dates)]\n",
    "    \n",
    "    # Encontrar el usuario con más tweets para cada una de las fechas top 10\n",
    "    top_users = df_top_10.groupby('date')['user'].agg(lambda x: x.value_counts().idxmax())\n",
    "\n",
    "    # Convertir el resultado a una lista de tuplas con (fecha, usuario)\n",
    "    result = [(date, user) for date, user in zip(top_10_dates, top_users)]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Ruta del archivo JSON a procesar\n",
    "file_path = '/Users/juanignaciomagarinoscastro/Downloads/farmers-protest-tweets-2021-2-4.json'\n",
    "q1_time(file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
