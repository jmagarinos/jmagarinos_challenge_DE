{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'jot__b'),\n",
       " (datetime.date(2021, 2, 18), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 15), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 20), 'Preetm91'),\n",
       " (datetime.date(2021, 2, 23), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 19), 'Surrypuria')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ujson\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Función para analizar un bloque de líneas del archivo JSON\n",
    "def parse_json_lines(lines: List[str]) -> List[Tuple[str, str]]:\n",
    "    result = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            # Intenta cargar el JSON de la línea\n",
    "            item = ujson.loads(line.strip())\n",
    "            # Verifica que los campos necesarios estén presentes antes de agregar\n",
    "            if 'date' in item and 'user' in item and 'id' in item:\n",
    "                result.append((item['date'], item['user']['username']))\n",
    "        except ValueError:\n",
    "            # Maneja errores de decodificación JSON\n",
    "            continue\n",
    "    return result\n",
    "\n",
    "# Función para paralelizar la lectura y procesamiento del archivo\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Lee el archivo en memoria\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        lines = json_file.readlines()\n",
    "\n",
    "    # Divide las líneas en bloques para procesamiento paralelo\n",
    "    num_threads = 16  # Ajustar basado en la cantidad de núcleos de CPU\n",
    "    chunk_size = len(lines) // num_threads\n",
    "    \n",
    "    # Usa ThreadPoolExecutor para paralelizar el análisis del JSON\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        # Envía tareas para procesar cada bloque de líneas en paralelo\n",
    "        futures = [executor.submit(parse_json_lines, lines[i:i + chunk_size]) for i in range(0, len(lines), chunk_size)]\n",
    "    \n",
    "    # Recoge los resultados de todos los hilos\n",
    "    data = []\n",
    "    for future in futures:\n",
    "        data.extend(future.result())\n",
    "\n",
    "    # Convierte la lista de tuplas en un DataFrame\n",
    "    df = pd.DataFrame(data, columns=['date', 'user'])\n",
    "    \n",
    "    # Convierte la columna 'date' a formato datetime.date\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # Obtiene las 10 fechas con más tweets\n",
    "    tweet_counts = df['date'].value_counts().nlargest(10)\n",
    "    top_10_dates = tweet_counts.index\n",
    "\n",
    "    # Filtra el DataFrame para incluir solo las fechas top 10\n",
    "    df_top_10 = df[df['date'].isin(top_10_dates)]\n",
    "\n",
    "    # Encuentra el usuario con más tweets para cada una de las fechas top 10\n",
    "    top_users = df_top_10.groupby('date')['user'].agg(lambda x: x.value_counts().idxmax())\n",
    "\n",
    "    # Convierte el resultado a una lista de tuplas (fecha, usuario)\n",
    "    result = [(date, user) for date, user in zip(top_10_dates, top_users)]\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Ruta del archivo JSON a procesar\n",
    "file_path = '/Users/juanignaciomagarinoscastro/Downloads/farmers-protest-tweets-2021-2-4.json'\n",
    "q1_time(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage before loading data: 39.40625 MB\n",
      "Memory usage after reading JSON: 1021.34375 MB\n",
      "Memory usage after parsing JSON with threads: 2976.9375 MB\n",
      "Memory usage after creating DataFrame: 4573.171875 MB\n",
      "Memory usage after filtering top 10 dates: 4625.453125 MB\n",
      "Memory usage after finalizing results: 4653.25 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 17), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 14), 'jot__b'),\n",
       " (datetime.date(2021, 2, 18), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 15), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 20), 'Preetm91'),\n",
       " (datetime.date(2021, 2, 23), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 19), 'Surrypuria')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ujson\n",
    "import psutil\n",
    "import os\n",
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Función para obtener el uso actual de memoria en MB\n",
    "def memory_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / 1024 / 1024  # Convertir a MB\n",
    "\n",
    "# Función para analizar un bloque de líneas del archivo JSON\n",
    "def parse_json_lines(lines: List[str]) -> List[Tuple[str, str]]:\n",
    "    result = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            # Intenta cargar el JSON de la línea\n",
    "            item = ujson.loads(line.strip())\n",
    "            # Verifica que los campos necesarios estén presentes antes de agregar\n",
    "            if 'date' in item and 'user' in item and 'id' in item:\n",
    "                result.append((item['date'], item['user']['username']))\n",
    "        except ValueError:\n",
    "            # Maneja errores de decodificación JSON\n",
    "            continue\n",
    "    return result\n",
    "\n",
    "# Función para paralelizar la lectura y procesamiento del archivo\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str]]:\n",
    "    # Imprime el uso de memoria antes de cargar los datos\n",
    "    print(f\"Memory usage before loading data: {memory_usage()} MB\")\n",
    "    \n",
    "    # Lee el archivo en memoria\n",
    "    with open(file_path, 'r') as json_file:\n",
    "        lines = json_file.readlines()\n",
    "\n",
    "    # Imprime el uso de memoria después de leer el JSON\n",
    "    print(f\"Memory usage after reading JSON: {memory_usage()} MB\")\n",
    "    \n",
    "    # Divide las líneas en bloques para procesamiento paralelo\n",
    "    num_threads = 24  # Ajustar basado en la cantidad de núcleos de CPU\n",
    "    chunk_size = len(lines) // num_threads\n",
    "    \n",
    "    # Usa ThreadPoolExecutor para paralelizar el análisis del JSON\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        # Envía tareas para procesar cada bloque de líneas en paralelo\n",
    "        futures = [executor.submit(parse_json_lines, lines[i:i + chunk_size]) for i in range(0, len(lines), chunk_size)]\n",
    "    \n",
    "    # Recoge los resultados de todos los hilos\n",
    "    data = []\n",
    "    for future in futures:\n",
    "        data.extend(future.result())\n",
    "\n",
    "    # Imprime el uso de memoria después de analizar el JSON con hilos\n",
    "    print(f\"Memory usage after parsing JSON with threads: {memory_usage()} MB\")\n",
    "    \n",
    "    # Convierte la lista de tuplas en un DataFrame\n",
    "    df = pd.DataFrame(data, columns=['date', 'user'])\n",
    "    \n",
    "    # Convierte la columna 'date' a formato datetime.date\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "    # Imprime el uso de memoria después de crear el DataFrame\n",
    "    print(f\"Memory usage after creating DataFrame: {memory_usage()} MB\")\n",
    "    \n",
    "    # Obtiene las 10 fechas con más tweets\n",
    "    tweet_counts = df['date'].value_counts().nlargest(10)\n",
    "    top_10_dates = tweet_counts.index\n",
    "\n",
    "    # Filtra el DataFrame para incluir solo las fechas top 10\n",
    "    df_top_10 = df[df['date'].isin(top_10_dates)]\n",
    "\n",
    "    # Imprime el uso de memoria después de filtrar las fechas top 10\n",
    "    print(f\"Memory usage after filtering top 10 dates: {memory_usage()} MB\")\n",
    "    \n",
    "    # Encuentra el usuario con más tweets para cada una de las fechas top 10\n",
    "    top_users = df_top_10.groupby('date')['user'].agg(lambda x: x.value_counts().idxmax())\n",
    "\n",
    "    # Convierte el resultado a una lista de tuplas (fecha, usuario)\n",
    "    result = [(date, user) for date, user in zip(top_10_dates, top_users)]\n",
    "    \n",
    "    # Imprime el uso de memoria después de finalizar los resultados\n",
    "    print(f\"Memory usage after finalizing results: {memory_usage()} MB\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Short file\n",
    "#file_path='/Users/juanignaciomagarinoscastro/Downloads/farmers-protest-tweets-2021-2-4.json'\n",
    "# Long file\n",
    "file_path = '/Users/juanignaciomagarinoscastro/Downloads/farmers-protest-tweets-2021-2-4-large.json'\n",
    "q1_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
